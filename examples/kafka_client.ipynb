{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka client\n",
    "This notebook gives an example of both kafka-python and confluent-kafka. The setup is to simply read a message form one topic (sensordata) and write to another (predictions).\n",
    "\n",
    "In the final solution this will not be a notebook, and there will of course be some model involved, but this is our MVP.\n",
    "\n",
    "Note that the required certificate files are on the NAS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kafka-python\n",
    "\n",
    "The open source version. Might lose messages? https://blog.datasyndrome.com/a-tale-of-two-kafka-clients-c613efab49df\n",
    "\n",
    "We first setup the consumer and producer, start reading and publishing messages, forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from kafka import KafkaConsumer, KafkaProducer\n",
    "\n",
    "def publish_message(producer_instance, topic_name, key, value):\n",
    "    try:\n",
    "        key_bytes = bytes(key, encoding='utf-8')\n",
    "        value_bytes = bytes(value, encoding='utf-8')\n",
    "        producer_instance.send(topic_name, key=key_bytes, value=value_bytes)\n",
    "        producer_instance.flush()\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "\n",
    "producer = KafkaProducer(bootstrap_servers=['sam01.ynformed.nl:9092'], \n",
    "                         api_version=(0, 10),\n",
    "                         ssl_certfile = \"kafka.client.pem\",\n",
    "                         ssl_keyfile = \"kafka.client.key\",\n",
    "                         security_protocol='SSL',\n",
    "                         ssl_check_hostname=True,\n",
    "                         ssl_cafile = \"ca-cert\")\n",
    "\n",
    "consumer = KafkaConsumer('sensordata', \n",
    "                         auto_offset_reset='earliest',\n",
    "                         bootstrap_servers=['sam01.ynformed.nl:9092'], \n",
    "                         api_version=(0, 10),\n",
    "                         consumer_timeout_ms=1000,\n",
    "                         security_protocol='SSL',\n",
    "                         ssl_check_hostname=True,\n",
    "                         ssl_certfile = \"kafka.client.pem\",\n",
    "                         ssl_keyfile = \"kafka.client.key\",\n",
    "                         ssl_cafile = \"ca-cert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we check the available topcis, just for show, and run the loop, this is all. Easy right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer.topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Started consume-produce loop...')\n",
    "while True:\n",
    "    for msg in consumer:\n",
    "        result = msg.value\n",
    "#         Uncomment to see the message\n",
    "#         print(result)\n",
    "        publish_message(producer, 'predictions', 'prediction', \n",
    "                        \"{'prediction': 0.34, 'input': \" + str(result) + \"}\")\n",
    "    sleep(5)\n",
    "    \n",
    "consumer.close()\n",
    "print(\"Ended, how did this happen?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confluent kafka\n",
    "\n",
    "Also included, because I don't know yet which is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, Producer\n",
    "\n",
    "kafka_consumer = Consumer(\n",
    "    {\n",
    "        \"api.version.request\": True,\n",
    "        \"enable.auto.commit\": True,\n",
    "        \"group.id\": 'jupyter-consumer',\n",
    "        \"bootstrap.servers\": 'sam01.ynformed.nl:9092',\n",
    "        \"security.protocol\": \"ssl\",\n",
    "        \"ssl.ca.location\": '/home/jovyan/ca-cert',\n",
    "        \"ssl.certificate.location\": '/home/jovyan/kafka.client.pem',\n",
    "        \"ssl.key.location\": '/home/jovyan/kafka.client.key',\n",
    "        \"default.topic.config\": {\"auto.offset.reset\": \"smallest\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "kafka_producer = Producer(\n",
    "    {\n",
    "        \"api.version.request\": True,\n",
    "        \"enable.auto.commit\": True,\n",
    "        \"group.id\": '1',\n",
    "        \"bootstrap.servers\": 'sam01.ynformed.nl:9092',\n",
    "        \"security.protocol\": \"ssl\",\n",
    "        \"ssl.ca.location\": '/home/jovyan/ca-cert',\n",
    "        \"ssl.certificate.location\": '/home/jovyan/kafka.client.pem',\n",
    "        \"ssl.key.location\": '/home/jovyan/kafka.client.key',\n",
    "        \"default.topic.config\": {\"auto.offset.reset\": \"smallest\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "kafka_consumer.subscribe(['sensordata'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_producer.list_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    msg = kafka_consumer.poll()\n",
    "    result = msg.value()\n",
    "#     print(result)\n",
    "    kafka_producer.produce('predictions', \"{'prediction': 0.34, 'input': \" + str(result) + \"}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
