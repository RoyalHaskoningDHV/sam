{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nepreda, or: A minimum viable project in SAM\n",
    "\n",
    "The goal of this notebook is to show how a project could be done (hopefully) relatively simple by using the SAM package, in addition to pandas and scikit-learn.\n",
    "\n",
    "This minimum viable project will still need the usual: problem definition, data collection, etcetera. This notebook assumes we already have our data, and we know our problem: predicting a certain column. (???) For the sake of completeness, we will show two possible problems: quantile regression, as well as binary classification.\n",
    "\n",
    "The project will consist of these steps:\n",
    "\n",
    "1. Loading the data - synthetic data will be loaded from sam.data_sources\n",
    "2. Plotting the data for visual inspection: This will not be comprehensive, because more work on this is planned in T224\n",
    "3. Preprocessing - using functions from sam.preprocessing to take out extreme or incorrect values\n",
    "4. Feature engineering - using sam.feature_engineering to create rolling features\n",
    "5. Feature selection - calculating autocorrelation using sam.feature_selection\n",
    "6. Modelling - doing quantile regression using scikit-garden\n",
    "7. Modelling - doing binary classification using scikit-learn\n",
    "8. Writing the results in such a way they can be visualized using the shiny dashboard being developed in T305\n",
    "\n",
    "Other:\n",
    "* Writing data to/from MongoDB in between steps\n",
    "* Logging results to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and magic needed for all sections.\n",
    "# A minor goal of this notebook is that every section can be executed independently. \n",
    "# However, for that to work, this cell needs to be executed before everything else.\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%aimport sam\n",
    "\n",
    "from sam.utils import MongoWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We load the (raw immutable) data using synthetic data. This snippet is quite long, because it's highly parameterized - these parameters were found with trial and error, and chosen to resemble nereda data as much as possible. Then, we write it to MongoDB.\n",
    "\n",
    "This (long) code is obviously not neccecary with a real project - there, you can just load the data from csv or whatever format. In that case, only the second cell in this section is needed, and the first cell can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.data_sources import synthetic_timeseries, synthetic_date_range\n",
    "\n",
    "def create_nereda_skeleton(start='2016-01-01', end='2017-05-01', freq='6H',\n",
    "                           unit_name='WSV_EPE_Nereda01',\n",
    "                           max_delay=700, random_stop_freq=0.002, random_stop_max_length=50):\n",
    "\n",
    "    index = synthetic_date_range(start, end, freq, max_delay, random_stop_freq, random_stop_max_length)\n",
    "\n",
    "    start_date = index[:-1]\n",
    "    end_date = index[1:]\n",
    "    # Id is unique for a reactor, but not for all reacors\n",
    "    id = np.random.choice(10**6, len(start_date), replace=False)\n",
    "    result = pd.DataFrame({'HistBatchStartDate': start_date.values,\n",
    "                           'HistBatchEndDate': end_date.values,\n",
    "                           'UnitName': unit_name, 'Id': id\n",
    "    }, columns=['HistBatchStartDate', 'HistBatchEndDate', 'UnitName', 'Id'])\n",
    "    return result\n",
    "\n",
    "\n",
    "def create_synthetic_nereda(units=['WSV_EPE_Nereda01', 'WSV_EPE_Nereda02'], **kwargs):\n",
    "\n",
    "    result = pd.DataFrame({})\n",
    "    for unit in units:\n",
    "        data = create_nereda_skeleton(unit_name = unit, **kwargs)\n",
    "        data['AERATION'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=5, daily=2, hourly=10, monthnoise=('normal', 3), daynoise=('normal', 0.2),\n",
    "                         noise={'normal': 0.1}, minmax_values=(10, 100), cutoff_values=None)\n",
    "        data['INFLUENT'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=2, daily=2, hourly=6, monthnoise=('normal', 0.5), daynoise=('poisson', 1),\n",
    "                         noise={'poisson': 0.1}, minmax_values=(0, 4000), cutoff_values=None, negabs=1500) + 200\n",
    "        data['NH4'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=0.1, daily=0.5, hourly=0.3, monthnoise=('poisson', 0.1), daynoise=('poisson', 0.3),\n",
    "                         noise={'normal': 0.1, 'poisson': 0.2}, minmax_values=(0, 25), cutoff_values=(0, 20))\n",
    "        data['NO3'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=6, daily=3, hourly=0.3, noise={'normal': 0.2, 'poisson': 0.5},\n",
    "                         minmax_values=(0, 21), cutoff_values=(0, 20))\n",
    "        data['PO4'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=0, daily=0.02, hourly=0, monthnoise=('normal', 0.0), daynoise=('poisson', 0.2),\n",
    "                         noise={'normal': 0.05, 'poisson': 0.01}, minmax_values=(0, 3), cutoff_values=None)\n",
    "        data['TEMPERATURE'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=5, daily=1, hourly=0.0, monthnoise=('normal', 0.01), daynoise=('normal', 0.01),\n",
    "                         noise={'normal': 0.1}, minmax_values=(5, 25), cutoff_values=None, random_missing=0.12)\n",
    "        data['TURBIDITY'] = synthetic_timeseries(data.HistBatchStartDate,\n",
    "                         monthly=0, daily=0.02, hourly=0, monthnoise=('normal', 0.0), daynoise=('poisson', 0.1),\n",
    "                         noise={'normal': 0.05, 'poisson': 0.01}, minmax_values=(0, 50), cutoff_values=None)\n",
    "        \n",
    "        firstvalid, lastvalid = data.AERATION.first_valid_index(), data.AERATION.last_valid_index()\n",
    "        data = data.iloc[firstvalid:lastvalid] # We get rid of the nans at the beginning/end due to the spline\n",
    "        result = pd.concat([result, data], ignore_index=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data (in this case from a synthetic data generator)\n",
    "data = create_synthetic_nereda(units=['WSV_EPE_Nereda01', 'WSV_EPE_Nereda02'], start='2010-01-01', end='2017-05-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use in exploration dashboard\n",
    "data.to_feather('synthetic_nereda.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data to mongoDB\n",
    "MongoWrapper('T277','raw_immutable').empty().add(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the data for visual inspection\n",
    "For now, I'm just going to do some basic time series plots, and use pandas profiling. In the future, SAM will offer more data exploration/visualization tools.\n",
    "\n",
    "The results of pandas_profiling can be [found here](http://10.2.0.20/pandasprofilingexample_sam.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "\n",
    "data = MongoWrapper('T277','raw_immutable').get().sort_values(['UnitName', 'HistBatchStartDate'])\n",
    "\n",
    "profile = pandas_profiling.ProfileReport(data)\n",
    "profile.to_file(outputfile=\"output.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows histograms, correlations and missing values. In this case there are no warnings, other than that TEMPERATURE has some missing values.\n",
    "# It does not show time series. To do that, we can do stuff like:\n",
    "\n",
    "# Helper function to show a line plot while preventing the date labels from overlapping\n",
    "def simple_timeseries(time, values, ix0=0, ix1=100):\n",
    "    %matplotlib inline\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot_date(time.iloc[ix0:ix1], values.iloc[ix0:ix1],\n",
    "                 marker='', linestyle='-')\n",
    "    fig.autofmt_xdate()\n",
    "    plt.show()\n",
    "\n",
    "simple_timeseries(data.HistBatchStartDate, data.NH4, 500, 700)\n",
    "simple_timeseries(data.HistBatchStartDate, data.PO4, 500, 700)\n",
    "# Etcetera. I'm not going to plot everything here because that's not the point.\n",
    "# In a real project, you would at least look at the data a little closer than I am to find unintuitive things that may be important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "In this secion, we will preprocess the data. For now that just involves getting rid of extreme values\n",
    "We are not going to 'complete' timestamps because that is not relevant for nereda, (because batches are discrete events)\n",
    "But complete_timestamps should be considered for other projects where the sensor data is not so discrete. You should also consider completing timestamps to fill gaps - lag features are not as meaningful if there are random gaps days or weeks between batches.\n",
    "\n",
    "In practice, other preprocessing steps will often need to be taken. These include project-specific steps, such as\n",
    "* Pivoting the table from long to wide\n",
    "* Adding a datetime object\n",
    "\n",
    "In fact, some of these steps may even need to be done before the previous step (visual inspection). \n",
    "Because this process is always highly project-specific, we cannot give general rules in this notebook, other than: Try to get the data into a standard dataframe format, with columns containing KPI's, and rows containing a unique sensor+time combination. In our example, we can skip some of this 'janitor' work, because the function 'create_synthetic_nereda' returns data that is already in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.preprocessing import correct_outside_range\n",
    "data = MongoWrapper('T277','raw_immutable').get()\n",
    "\n",
    "data = correct_outside_range(data, 'NH4', (0, 20), 'na')\n",
    "data = correct_outside_range(data, 'NO3', (0, 20), 'na')\n",
    "data = correct_outside_range(data, 'PO4', (0, 10), 'na')\n",
    "data = correct_outside_range(data, 'TURBIDITY', (0, 50), 'na')\n",
    "\n",
    "MongoWrapper('T277','preprocessed').empty().add(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "This pipeline is where engineering comes in. This is just an example. Also, consider the tsfresh package, which has many feature engineering functions for time series.\n",
    "\n",
    "This section just shows some of the possibilities of the SAM package. In the future, 'standard' feature engineering may be added to SAM, as a suggestion of what features can be used. This way, some of the feature engineering will be done for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class: use FunctionTransformer with get_feature_names\n",
    "# Only works if the function returns a pandas dataframe (or other object with .column.values attribute)\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "class FunctionTransformerWithNames(FunctionTransformer):\n",
    "    def transform(self, X, y='deprecated'):\n",
    "        output = super(FunctionTransformerWithNames, self).transform(X, y)\n",
    "        self._feature_names = list(output.columns.values)\n",
    "        return output\n",
    "    def get_feature_names(self):\n",
    "        return self._feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MongoWrapper('T277','raw_immutable').get()\n",
    "\n",
    "# Project specific feature engineering:\n",
    "# although these features are not super creative, they should probably be used in any project with discrete batches\n",
    "data['BATCH_DURATION'] = (data.HistBatchEndDate - data.HistBatchStartDate).dt.seconds\n",
    "# This column is pretty useless because it's always 0... But lets see if it's filtered out during feature selection!\n",
    "data['TIME_SINCE_PREVIOUS'] = data.groupby('UnitName').apply(lambda x: (x.HistBatchStartDate - x.HistBatchEndDate.shift()).dt.seconds).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sam.feature_engineering.rolling_features import BuildRollingFeatures\n",
    "from sam.feature_engineering import decompose_datetime\n",
    "\n",
    "# Showing the possibilities of the ColumnTransformer together with BuildRollingFeatures\n",
    "# This can maybe be made a bit easier:\n",
    "# - make keep_original False a default\n",
    "# - make a built-in decompose_datetime with get_feature_names\n",
    "\n",
    "# However, the idea of a large transformer pipeline is still useful. Ideally, we would even add the previous cell to this as well.\n",
    "\n",
    "\n",
    "kpi_cols = ['INFLUENT','NH4','NO3','PO4','TEMPERATURE','TURBIDITY','BATCH_DURATION','TIME_SINCE_PREVIOUS']\n",
    "fourier_cols = ['INFLUENT','NH4','NO3','PO4','TEMPERATURE','TURBIDITY']\n",
    "time_cols = ['HistBatchStartDate']\n",
    "\n",
    "# Make decompose_datetime work with FeatureTransformerWithNames\n",
    "time_transformer = lambda dates: decompose_datetime(dates, 'HistBatchStartDate', ['hour', 'day', 'month', 'weekday'])\n",
    "\n",
    "nereda_features = Pipeline([\n",
    "    (\"kpi_lags\", ColumnTransformer([\n",
    "        # Lag features\n",
    "        (\"lag\", BuildRollingFeatures(rolling_type='lag', window_size = [1,2], lookback=0, keep_original=False), kpi_cols),\n",
    "\n",
    "        # Summary of the last week\n",
    "        (\"max_week\", BuildRollingFeatures(rolling_type='max', window_size = 28, keep_original=False), kpi_cols),\n",
    "        (\"min_week\", BuildRollingFeatures(rolling_type='min', window_size = 28, keep_original=False), kpi_cols),\n",
    "        (\"mean_week\", BuildRollingFeatures(rolling_type='mean', window_size = 28, keep_original=False), kpi_cols),\n",
    "\n",
    "        # Summary of the last day\n",
    "        (\"max_day\", BuildRollingFeatures(rolling_type='max', window_size = 4, keep_original=False), kpi_cols),\n",
    "        (\"min_day\", BuildRollingFeatures(rolling_type='min', window_size = 4, keep_original=False), kpi_cols),\n",
    "        (\"mean_day\", BuildRollingFeatures(rolling_type='mean', window_size = 4, keep_original=False), kpi_cols),\n",
    "\n",
    "        # Fourier features\n",
    "        (\"fourier\", BuildRollingFeatures(rolling_type='fourier', window_size = 28, keep_original=False), fourier_cols),\n",
    "        \n",
    "        (\"timefeats\", FunctionTransformerWithNames(time_transformer, validate=False), time_cols),\n",
    "        \n",
    "        # Also use the kpi_cols themselves as features because why not. This is much easier than concatting them later\n",
    "        # the FunctionTransformerWithNames is trivial, but is needed to get 'get_feature_names' to work\n",
    "        (\"passthrough\", FunctionTransformerWithNames(lambda x: x, validate=False), kpi_cols)\n",
    "    ], remainder='drop'))  # Drop the useless 'Id' column. Columns can be passed through if needed, see documentation of ColumnTransformer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to continue by training a different model for each reactor.\n",
    "# If this is not desired, some sklearn finagling will have to be done to prevent errors\n",
    "# (e.g.: lag will leak a little bit if there are multiple reactors in the dataframe)\n",
    "reactor = \"WSV_EPE_Nereda01\"\n",
    "data = data.query('UnitName == \"{}\"'.format(reactor)).sort_values(['HistBatchStartDate'])  # data must be sorted for RollingFeatures\n",
    "\n",
    "# Apply the sklearn pipeline.\n",
    "result = nereda_features.fit_transform(data)\n",
    "result = pd.DataFrame(result, columns = nereda_features.named_steps['kpi_lags'].get_feature_names())\n",
    "\n",
    "# Write it to the table: features_WSV_EPE_Nereda01\n",
    "MongoWrapper('T277','features_{}'.format(reactor)).empty().add(result)\n",
    "result.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "We now have 160 features (and 1 target). This means it may be time to do a little feature selection! There are many methods of feature selection, and it is reccommended to use one of the many great methods already in sklearn! We did not reimplement them in SAM, because they are already in sklearn!\n",
    "\n",
    "For example, we could train a simple random forest model, and choose only those features with the highest feature importance. In this section, we don't show that (just google it or something), but we show three other methods of feature selection.\n",
    "\n",
    "* Sklearn - SelectKBest\n",
    "* Sam - top_correlations\n",
    "* autocorrelation plot\n",
    "\n",
    "Importantly! feature selection in a real project should be done on train data only, instead of on all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.feature_selection.top_correlation import retrieve_top_n_correlations\n",
    "reactor = \"WSV_EPE_Nereda01\"\n",
    "target = 'passthrough__NH4'\n",
    "\n",
    "data = MongoWrapper('T277','features_{}'.format(reactor)).get()\n",
    "y = data[[target]]\n",
    "X = data.drop([target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SelectKBest is the easiest to get a proof-of-concept. In just a few lines of code, we pick the most useful columns.\n",
    "# However, it is probably the hardest to explain to a customer. Also, you need to be careful in deployment: fit_transform will not always return the same columns.\n",
    "# f_score is a widely applicable score. In a project, probably think about it a little if you want to use chi2 or mi or f_score (or even correlation)\n",
    "\n",
    "# IMPORTANT: for now, it doesn't work because of missing values... I chose to ignore it because this is not sam functionality, but just showing an alternative.\n",
    "\n",
    "if False:\n",
    "    from sklearn.feature_selection import SelectKBest, f_regression\n",
    "    feature_selector = SelectKBest(f_regression, k=50).fit(X, y)\n",
    "    X_new = feature_selector.transform(X)\n",
    "\n",
    "# If you just want feature selection with pearson without manual work, I would reccommend using the 'abs_pearson_correlation' function shown here, \n",
    "# and just use SelectKBest as seen above (replace f_regression with abs_person_correlation)\n",
    "\n",
    "def abs_pearson_corr(X, y):\n",
    "    from scipy.stats import pearsonr\n",
    "    corr_and_p = np.apply_along_axis(lambda x: pearsonr(x, y), 0, X)\n",
    "    return(np.abs((corr_and_p[0, :]), corr_and_p[1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method is less 'easy', but more of an exploration tactic.\n",
    "# This method is more meant for manual inspection, and perhaps even visualization in a bar plot of sorts\n",
    "result = retrieve_top_n_correlations(data, target, 100, grouped=False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.bar(result[['index']][:10].values.ravel(), result[[target]][:10].values.ravel())\n",
    "plt.xticks(rotation=90)\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autocorrelation plot\n",
    "# not implemented yet. See T352\n",
    "\n",
    "from sam.feature_selection.lag_correlation import create_lag_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification\n",
    "\n",
    "For this example, we will be using 'passthrough__NH4' as the target, and will be doing binary classification: is there an incident coming up.\n",
    "Predicting incidents in the future instead of only for the current moment is obviously more interesting. Therefore, our goal variable will become: 'is there an incident coming up in the next 1-5 datapoints? Here, 1-5 is an arbitrary choice. Incident is defiend as 'passthrough__NH4' > 10 for a specific datapoint.\n",
    "10 is chosen the same as Nereda, although the synthetic data does not neccecarily have the same proportion of > 10 as the original data did.\n",
    "Incident recall is defined here: http://10.2.0.20/sam/metrics.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.visualization import make_incident_heatmap\n",
    "\n",
    "reactor = \"WSV_EPE_Nereda01\"\n",
    "target = 'passthrough__NH4'\n",
    "cutoff = 10\n",
    "data = MongoWrapper('T277','features_{}'.format(reactor)).get()\n",
    "\n",
    "data['id'] = reactor\n",
    "data['incident'] = data[[target]].values.ravel() > cutoff\n",
    "\n",
    "# Step 1: see how many incidents there even are\n",
    "# The date labels are very ugly, but will hopefully be fixed in the future. See T353\n",
    "make_incident_heatmap(data, resolution='W', time_column='timefeats__HistBatchStartDate', cmap='Reds', datefmt=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the actual modelling.\n",
    "# This is also where MLFlow comes in.\n",
    "\n",
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://10.2.0.20:5000\")\n",
    "\n",
    "# This create_experiment will fail because it's already created.\n",
    "# Therefore, we rely on a magic number.\n",
    "# experiment_id = mlflow.create_experiment('sam_demo_T277')\n",
    "experiment_id = 21\n",
    "\n",
    "reactor = \"WSV_EPE_Nereda01\"\n",
    "data = MongoWrapper('T277','features_{}'.format(reactor)).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GroupShuffleSplit, GridSearchCV\n",
    "from sam.feature_engineering import range_lag_column\n",
    "\n",
    "target = 'passthrough__NH4'\n",
    "cutoff = 10\n",
    "range_pred = (1, 5)\n",
    "\n",
    "# Here we finally calculate the actual target column. Did an incident happen in the next 1-5 datapoints?\n",
    "# If an incident happens in the current data point, it's not interesting, because we already know there is an incident happening\n",
    "# We want to predict: is there an incident coming up in the future?\n",
    "data['outcome'] = range_lag_column(data[target] > cutoff, range_pred)\n",
    "\n",
    "drop_cols = ['timefeats__HistBatchStartDate', 'outcome']  # To be dropped from X later.\n",
    "# target can just be used, because we want to predict the FUTURE value, not the current value. Of course 'outcome' is not okay to use.\n",
    "\n",
    "# We save a holdout set, to try the performance on later.\n",
    "holdout = data.loc[data['timefeats__HistBatchStartDate'].dt.year == 2017]\n",
    "cv_set = data.loc[data['timefeats__HistBatchStartDate'].dt.year < 2017]\n",
    "\n",
    "# We use group shuffle split. This ensures the splits are fair: years are always kept together.\n",
    "year_split = cv_set['timefeats__HistBatchStartDate'].dt.year\n",
    "\n",
    "y = cv_set['outcome']\n",
    "X = cv_set.drop(drop_cols, axis=1)\n",
    "\n",
    "\n",
    "# RF doesn't take NaN for an answer, so fill with -9999\n",
    "X = X.fillna(-99999)\n",
    "\n",
    "# It's scikit-learn time!\n",
    "# As mentioned in the Feature Selection section, feature selection should ideally be done on only the train set\n",
    "# This is where this can be configured, in the 'estimator' parameter. This could be a pipeline (and in fact, that is reccommended!)\n",
    "# Alternitively, we can forego gridsearch and just use a single train/test split. (in this case, a pipeline is still a good idea!)\n",
    "grid_search_params = {\n",
    "    \"estimator\" : RandomForestClassifier(n_estimators = 50, min_samples_split = 10),\n",
    "    \"scoring\" : \"roc_auc\",\n",
    "    \"n_jobs\" : -1,\n",
    "    \"cv\" : GroupShuffleSplit(n_splits = 5, train_size = 0.8, test_size = 0.2, random_state = 42).split(X, y, year_split),\n",
    "    \"param_grid\" : {\n",
    "        \"class_weight\" : [None, \"balanced\"]\n",
    "    },\n",
    "    \"return_train_score\" : True,\n",
    "    \"iid\" : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the actual machine learning\n",
    "clf = GridSearchCV(**grid_search_params)\n",
    "_ = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that ML is done, we cal start logging to MLFlow\n",
    "import mlflow.sklearn as mlflow_sklearn\n",
    "# Also show off some visualizations from sam\n",
    "from sam.visualization import make_precision_recall_curve\n",
    "# We don't have make_precision_incident_recall_curve yet, but will probably be added in the future\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sam.metrics import incident_recall\n",
    "\n",
    "# There can be multiple results, after all, we are doing grid search\n",
    "# In this case, we only try 2 variations: class_weight is either None or \"balanced\"\n",
    "# Each parameter set trains multiple models, but only gives 1 record\n",
    "# If you are not doing parameter search, this is obviously useless\n",
    "# However, the code will only be more straightforward if you don't do grid search, but just a single model.\n",
    "all_results = pd.DataFrame(clf.cv_results_)\n",
    "    \n",
    "# holdout scoring\n",
    "y_incidents = holdout[target] > cutoff\n",
    "X_holdout = holdout.drop(drop_cols, axis=1)\n",
    "X_holdout = X_holdout.fillna(-99999)\n",
    "y_holdout = holdout[\"outcome\"]\n",
    "\n",
    "y_pred = clf.best_estimator_.predict(X_holdout)\n",
    "y_pred_proba = clf.best_estimator_.predict_proba(X_holdout)\n",
    "\n",
    "ax = make_precision_recall_curve(y_holdout, [a[1] for a in y_pred_proba])\n",
    "\n",
    "ax.figure.savefig(\"output/visualizations/precision_recall_curve.png\")\n",
    "plt.close()\n",
    "\n",
    "for i, result in all_results.iterrows():\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "        # Overall parameters\n",
    "        mlflow.log_param(\"Target\", target)\n",
    "        mlflow.log_param(\"Cutoff\", cutoff)\n",
    "        mlflow.log_param(\"range_pred\", str(range_pred))\n",
    "\n",
    "        for key in grid_search_params:\n",
    "            mlflow.log_param(key, str(grid_search_params[key]).replace('\\n', ' '))\n",
    "\n",
    "        # Result of GridSearchCV\n",
    "        params = result[\"params\"]\n",
    "        for key, value in result.items():\n",
    "            if ((key == \"params\") | key.startswith(\"param_\")):\n",
    "                continue\n",
    "            mlflow.log_metric(key, value)\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        # Holdout metrics\n",
    "        mlflow.log_metric(\"Holdout number_positive\", np.sum(y_holdout))\n",
    "        mlflow.log_metric(\"Holdout percentage_positive\", np.sum(y_holdout) / y_holdout.size)\n",
    "        mlflow.log_metric(\"Holdout number_of_incidents\", np.sum(y_incidents))\n",
    "        mlflow.log_metric(\"Holdout total_size\", y_holdout.size)\n",
    "        mlflow.log_metric(\"Holdout precision\", precision_score(y_holdout, y_pred))\n",
    "        mlflow.log_metric(\"Holdout Recall\", recall_score(y_holdout, y_pred))\n",
    "        mlflow.log_metric(\"Holdout Incident recall\", incident_recall(y_incidents, y_pred, range_pred))\n",
    "        mlflow.log_metric(\"Holdout Incident recall plus one\", incident_recall(y_incidents, y_pred, (range_pred[0] + 1, range_pred[1])))\n",
    "        mlflow.log_metric(\"Holdout auc\", roc_auc_score(y_holdout, [a[1] for a in y_pred_proba]))\n",
    "\n",
    "        # Misscelaneous and artifcats\n",
    "        with open(\"output/visualizations/features.txt\", 'w') as filetowrite:\n",
    "            filetowrite.write(str(list(X.columns.values)))\n",
    "            filetowrite.close()\n",
    "        mlflow.log_artifact(\"output/visualizations/features.txt\")\n",
    "        mlflow_sklearn.log_model(grid_search_params[\"estimator\"], \"estimator_unfit\")\n",
    "        mlflow_sklearn.log_model(clf.best_estimator_, \"best_estimator\")\n",
    "        mlflow.log_artifact(\"output/visualizations/precision_recall_curve.png\")\n",
    "\n",
    "        if hasattr(clf.best_estimator_, 'feature_importances_'):\n",
    "            with open(\"output/visualizations/feature_importance.txt\", 'w') as filetowrite:\n",
    "                tuples = zip(list(clf.best_estimator_.feature_importances_), list(X.columns.values))\n",
    "                tuples = sorted(tuples, reverse = True)\n",
    "                result = \"\\n\".join([name + \": \" + str(imp) for imp, name in tuples])\n",
    "                filetowrite.write(result)\n",
    "                filetowrite.close()\n",
    "            mlflow.log_artifact(\"output/visualizations/feature_importance.txt\")\n",
    "\n",
    "\n",
    "# See the results here:\n",
    "# http://10.2.0.20:5000/#/experiments/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile Regression\n",
    "\n",
    "In this section, show off quantile regression. No MLFlow because I'm just trying to get this done. ¯\\\\_(ツ)_/¯\n",
    "\n",
    "In this case, we are showing off just a single model. The process of turning it into a grid search and adding mlflow is the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skgarden import RandomForestQuantileRegressor\n",
    "\n",
    "reactor = \"WSV_EPE_Nereda01\"\n",
    "target = 'passthrough__NH4'\n",
    "\n",
    "data = MongoWrapper('T277','features_{}'.format(reactor)).get()\n",
    "\n",
    "# We save a holdout set, to try the performance on later.\n",
    "test = data.loc[data['timefeats__HistBatchStartDate'].dt.year == 2017]\n",
    "train = data.loc[data['timefeats__HistBatchStartDate'].dt.year < 2017]\n",
    "drop_cols = ['timefeats__HistBatchStartDate', target]\n",
    "\n",
    "# For quantile regression, an important point counts: we don't use the target column, but we often want to use some lagged version of the target\n",
    "# This lag depends on what kind of outliers we are trying to detect: long or short-term outliers. This is a longstanding discussion at hydrotwin...\n",
    "# In this case, we use all kind of lagged variables, so it's extremely short-term outliers... :) Obviously in practice, you probably want to\n",
    "# change the feature generating pipeline a little bit to not include 20+ different short-term lagged versions of the target, but maybe just 1 or 2.\n",
    "\n",
    "y_train = train[target]\n",
    "X_train = train.drop(drop_cols, axis=1)\n",
    "# RF doesn't take NaN for an answer, so fill with -9999\n",
    "X_train = X_train.fillna(-99999)\n",
    "y_train = y_train.fillna(-1) # Bit hacky... oh well\n",
    "\n",
    "# Potentially do feature selection here. Not for now.\n",
    "clf = RandomForestQuantileRegressor(min_samples_split=10, n_estimators=50, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the machine learning\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test[target]\n",
    "X_test = test.drop(drop_cols, axis=1)\n",
    "X_test = X_test.fillna(-99999)\n",
    "\n",
    "lower = clf.predict(X_test, quantile=20)\n",
    "medium = clf.predict(X_test, quantile=50)\n",
    "upper = clf.predict(X_test, quantile=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam.train_models import find_outlier_curves\n",
    "\n",
    "dashboard_data = pd.DataFrame({\n",
    "    \"TIME\": test.timefeats__HistBatchStartDate,\n",
    "    \"PREDICT\": medium,\n",
    "    \"ACTUAL\": y_test,\n",
    "    \"ID\": reactor,\n",
    "    \"PREDICT_LOW\": lower,\n",
    "    \"PREDICT_HIGH\": upper\n",
    "}).reset_index()\n",
    "# Now calculate the outlier 'curves'\n",
    "# For more information, see documentation.\n",
    "# Batches are 6 hours, quite long, so default parameters will work fine. (no gaps, etc.)\n",
    "dashboard_data[\"OUTLIER\"] = find_outlier_curves(dashboard_data)\n",
    "\n",
    "dashboard_data.to_csv(\"output/quantile_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate outliers per week.\n",
    "# Useful for making a heatmap\n",
    "from sam.visualization import make_incident_heatmap\n",
    "dashboard_data['incident'] = dashboard_data.OUTLIER > 0\n",
    "make_incident_heatmap(dashboard_data, resolution=\"W\", row_column=\"ID\", time_column=\"TIME\", cmap=\"Reds\", datefmt=\"%Y, week %W\")\n",
    "\n",
    "# Calculate the grouped_df ourself (copying code from the heatmap function)\n",
    "df_grouped = dashboard_data.groupby([\"ID\", pd.Grouper(key=\"TIME\", freq=\"W\")])\n",
    "df_grouped = df_grouped[\"incident\"].sum().unstack(fill_value=0).transpose().reset_index()\n",
    "df_grouped.head(5)\n",
    "\n",
    "df_grouped.to_csv(\"output/heatmap_output.csv\")\n",
    "\n",
    "# These two files can now be read in R and used to make a nice, material dashboard :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential next steps\n",
    "\n",
    "This document covered the first steps of exploring the data, fixing issues, and eventually training a model. One of the next steps should be making your code more reproducible, by moving the individual parts (preprocessing, feature engineering, etc) to functions, and away from a jupyter notebook. Then, the potential trained models should eventually be pickled, and moved to production somehow. When moving to production, an actual 'pipeline' can also be very useful as a method to automatically preprocess and train/predict. "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
